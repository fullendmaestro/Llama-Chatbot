{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TA4iS6Qao382",
        "outputId": "8e86ba71-23fe-402a-8e3c-b1d15164bd58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/huggingface/transformers\n",
            "  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-gu09y79w\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-gu09y79w\n",
            "  Resolved https://github.com/huggingface/transformers to commit f2c388e3f946862f657acc1e21b272ec946fc66c\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.34.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (3.20.3)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.24.7)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.46.0.dev0) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.46.0.dev0) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers==4.46.0.dev0) (0.20.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.46.0.dev0) (4.66.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.46.0.dev0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.46.0.dev0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.46.0.dev0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.46.0.dev0) (2024.8.30)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install accelerate protobuf sentencepiece torch git+https://github.com/huggingface/transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "zWGkVIXHJDUo"
      },
      "outputs": [],
      "source": [
        "!pip -q install openai pinecone-client gradio sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "e0qYFO8d3SEm"
      },
      "outputs": [],
      "source": [
        "# API Keys from colab secret for Hugging Face, OpenAI, and Pinecone\n",
        "from google.colab import userdata\n",
        "pinecone_api_key = userdata.get('PINECONE_API_KEY')\n",
        "huggingface_api_key = userdata.get('HUGGINGFACEHUB_API_TOKEN')\n",
        "openai_api_key = userdata.get('OPENAI_API_KEY')\n",
        "pinecone_region = userdata.get('PINECONE_ENV')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "qmQWrMVIpW9G"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "from huggingface_hub import login\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwyGNz53qR0B",
        "outputId": "0acc01e7-5b7a-4b31-d072-9ac32f3e1ab8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: read).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ],
      "source": [
        "# Hugging Face Authentication\n",
        "login(token=huggingface_api_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "NvcWebwwql0y"
      },
      "outputs": [],
      "source": [
        "# Define the paths for the CSV files\n",
        "products_csv = 'products.csv'\n",
        "qa_csv = 'qa_dataset.csv'\n",
        "troubleshooting_csv = 'troubleshooting.csv'\n",
        "\n",
        "\n",
        "\n",
        "# Load the existing CSV file into a DataFrame\n",
        "qa_df = pd.read_csv(qa_csv)\n",
        "products_df = pd.read_csv(products_csv)\n",
        "troubleshooting_df = pd.read_csv(troubleshooting_csv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWPB9c9Hqv14",
        "outputId": "216e3ecd-0851-46bc-bb0c-76a6b6aac62c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "QA Dataset:\n",
            "                                            Question  \\\n",
            "0  My SmartHome Hub won't connect to Wi-Fi. What ...   \n",
            "1  The temperature readings on my Smart Thermosta...   \n",
            "2  My Smart Lights won't turn on or off using the...   \n",
            "3  The Smart Lock isn't responding to app command...   \n",
            "4  My Smart Security Camera isn't showing a live ...   \n",
            "\n",
            "                                              Answer  \n",
            "0  I understand you're having trouble connecting ...  \n",
            "1  I'm sorry to hear your Smart Thermostat is sho...  \n",
            "2  I see you're having issues controlling your Sm...  \n",
            "3  I understand your Smart Lock isn't responding ...  \n",
            "4  I'm sorry to hear you're not getting a live fe...  \n",
            "\n",
            "Products Dataset:\n",
            "                           Title  \\\n",
            "0              SmartHome Hub Pro   \n",
            "1      EcoTherm Smart Thermostat   \n",
            "2      LuminaGlow Smart Bulb Set   \n",
            "3         SecureGuard Smart Lock   \n",
            "4  ClearView Pro Security Camera   \n",
            "\n",
            "                                         Description  \n",
            "0  Control your entire smart home ecosystem with ...  \n",
            "1  Save energy and money with the EcoTherm Smart ...  \n",
            "2  Transform your home lighting with the LuminaGl...  \n",
            "3  Enhance your home security with the SecureGuar...  \n",
            "4  Keep an eye on your property with the ClearVie...  \n",
            "\n",
            "Troubleshooting Dataset:\n",
            "                  Device                           Issue  \\\n",
            "0          SmartHome Hub          Won't connect to Wi-Fi   \n",
            "1       Smart Thermostat  Incorrect temperature readings   \n",
            "2           Smart Lights  Not responding to app commands   \n",
            "3             Smart Lock    Battery draining too quickly   \n",
            "4  Smart Security Camera              Poor video quality   \n",
            "\n",
            "                                               Steps  \n",
            "0  Ensure your Wi-Fi network is operational\\nChec...  \n",
            "1  Check if the thermostat is placed away from di...  \n",
            "2  Verify that your smartphone and smart lights a...  \n",
            "3  Check if the lock is properly installed with n...  \n",
            "4  Check your internet connection speed\\nEnsure t...  \n"
          ]
        }
      ],
      "source": [
        "# Verify the CSV content\n",
        "print(\"QA Dataset:\")\n",
        "print(qa_df.head())\n",
        "\n",
        "print(\"\\nProducts Dataset:\")\n",
        "print(products_df.head())\n",
        "\n",
        "print(\"\\nTroubleshooting Dataset:\")\n",
        "print(troubleshooting_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "z3PTvt2-hQ6j"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uoIRUs1vG4q9",
        "outputId": "95f2e167-8e01-432a-da50-f6051cdd2a99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from pinecone import Pinecone, ServerlessSpec\n",
        "import openai\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "\n",
        "# Load the sentence transformer model\n",
        "embedding_model = SentenceTransformer('sentence-transformers/multi-qa-mpnet-base-cos-v1')\n",
        "\n",
        "# Initialize Pinecone\n",
        "pc = Pinecone(api_key=pinecone_api_key)\n",
        "\n",
        "# Pinecone index name\n",
        "index_name = \"llama-quest-index\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "XNxr5CYJFuLV"
      },
      "outputs": [],
      "source": [
        "# Check if the index exists, if not, create it\n",
        "if index_name not in pc.list_indexes():\n",
        "    pc.create_index(\n",
        "        name=index_name,\n",
        "        dimension=768,  # Embedding dimension for 'sentence-transformers/multi-qa-mpnet-base-cos-v1'\n",
        "        metric=\"cosine\",\n",
        "        spec=ServerlessSpec(\n",
        "            cloud=\"aws\",\n",
        "            region=pinecone_region\n",
        "        )\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "_BTfveCUGHeA"
      },
      "outputs": [],
      "source": [
        "# Connect to the Pinecone index\n",
        "index = pc.Index(index_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "RHkSCn0zzBYE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "NSbBtsySHS3g"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "wFJONp7QHZER"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "b2c3e3ec35e3451cb32445920843368f",
            "6c687402d9b94ae5ad29c91bc839f37c",
            "ae88ee4eda7a4b65811dd32b458690fa",
            "40275e9630b64570bdf08d6cad88dc34",
            "4daa9e93e7cb4842a6f14699a67bec0e",
            "be6f69373db74952bad8015b26f842af",
            "1747c633002d47428b44092fc48e8c68",
            "2e3cfb865d904f92b7449a036b1fcf4b",
            "90fce2dda3f5421aba024005b705601c",
            "1769640cfbaa405895b4e66ba18d779f",
            "5cfe910ed2824bf8a1a9c482c9128e45"
          ]
        },
        "id": "I8mwwbHcq_oK",
        "outputId": "072cbe3e-7a6e-4497-8717-55a7decb8a36"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b2c3e3ec35e3451cb32445920843368f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu and disk.\n"
          ]
        }
      ],
      "source": [
        "# Initialize the Llama 2 model and tokenizer\n",
        "model_id = \"NousResearch/Llama-2-7b-chat-hf\"\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.float16, device_map=\"auto\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "tokenizer.use_default_system_prompt = False\n",
        "\n",
        "# Initialize the pipeline using Hugging Face pipeline\n",
        "llama_pipeline = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\",\n",
        "    max_length=1024,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "0_iL0VkfGKjg"
      },
      "outputs": [],
      "source": [
        "# Embed and store documents in Pinecone\n",
        "def embed_and_store_documents(df, text_column, namespace, metadata_columns=None):\n",
        "    if metadata_columns is None:\n",
        "        metadata_columns = []  # Ensure it's an empty list if not provided\n",
        "\n",
        "    for idx, row in df.iterrows():\n",
        "        # Handle text_column being a list or string\n",
        "        text = row[text_column] if isinstance(text_column, str) else ' '.join([str(row[col]) for col in text_column])\n",
        "\n",
        "        # Embed the text using the sentence-transformers model\n",
        "        embedding = embedding_model.encode(text).tolist()  # Convert to list format for Pinecone\n",
        "\n",
        "        # Extract metadata\n",
        "        metadata = {col: row[col] for col in metadata_columns}  # Handle metadata columns\n",
        "\n",
        "        # Insert into Pinecone with unique ID (index)\n",
        "        index.upsert([(str(idx), embedding, metadata)], namespace=namespace)\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Y0TtSqO9bKoh"
      },
      "outputs": [],
      "source": [
        "# Function to load datasets and index them correctly\n",
        "def index_datasets():\n",
        "    # Load datasets\n",
        "    qa_df = pd.read_csv('qa_dataset.csv')\n",
        "    products_df = pd.read_csv('products.csv')\n",
        "    troubleshooting_df = pd.read_csv('troubleshooting.csv')\n",
        "\n",
        "    # Index QA dataset: Use \"Answer\" as document, \"Question\" as metadata\n",
        "    embed_and_store_documents(qa_df, 'Answer', 'qa', metadata_columns=['Question'])\n",
        "\n",
        "    # Index Products dataset: Use \"Description\" as document, \"Title\" as metadata\n",
        "    embed_and_store_documents(products_df, 'Description', 'products', metadata_columns=['Title'])\n",
        "\n",
        "    # Index Troubleshooting dataset: Concatenate \"Issue\" and \"Steps\" for document, \"Device\" as metadata\n",
        "    embed_and_store_documents(troubleshooting_df, ['Issue', 'Steps'], 'troubleshooting', metadata_columns=['Device'])\n",
        "\n",
        "# Run the indexing process\n",
        "index_datasets()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "TJaSPHskHvRb"
      },
      "outputs": [],
      "source": [
        "# Semantic search function using Pinecone\n",
        "def semantic_search(query, namespace):\n",
        "    # Use sentence-transformers to encode the query\n",
        "    query_embedding = embedding_model.encode(query).tolist()\n",
        "\n",
        "    # Query Pinecone\n",
        "    results = index.query(\n",
        "        vector=query_embedding,  # The query embedding\n",
        "        top_k=3,  # Top 3 results\n",
        "        include_metadata=True,  # Include metadata in the results\n",
        "        namespace=namespace  # Search in the specified namespace\n",
        "    )\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "U4EBVJzUbp6c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "xs55mw_IKnY7"
      },
      "outputs": [],
      "source": [
        "# Function to generate a response with context from the search results\n",
        "def generate_with_context(question, search_results):\n",
        "    # Prepare the context from search results\n",
        "    if search_results:\n",
        "        best_match = search_results[0]['metadata']  # Assuming metadata holds relevant information\n",
        "        context = f\"Context: {best_match}\\n\\n\"\n",
        "        full_prompt = f\"{context}User Question: {question}\\n\\nAI Response:\"\n",
        "    else:\n",
        "        # No search results, just use the question\n",
        "        full_prompt = f\"User Question: {question}\\n\\nAI Response:\"\n",
        "\n",
        "    # Generate response using Llama-2\n",
        "    response = llama_pipeline(full_prompt, max_length=200, do_sample=True)[0]['generated_text']\n",
        "    return response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EsrBNaK7uWH_"
      },
      "outputs": [],
      "source": [
        "# Main function to handle a user's question and provide an answer\n",
        "def answer_question(question, history):\n",
        "    # Perform semantic search across multiple namespaces (QA, products, troubleshooting)\n",
        "    search_results = []\n",
        "    search_results.extend(semantic_search(question, 'qa').matches)\n",
        "    search_results.extend(semantic_search(question, 'products').matches)\n",
        "    search_results.extend(semantic_search(question, 'troubleshooting').matches)\n",
        "\n",
        "    # Generate answer using the search results as context\n",
        "    response = generate_with_context(question, search_results)\n",
        "    return response\n",
        "\n",
        "res = answer_question(\"Smart tv misbehaving\", [])\n",
        "res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "hzRM45pNu7o8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xWYLK6nslaP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "Hz_QGPnavIJA"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "\n",
        "# Gradio chat interface\n",
        "def gradio_chat_interface(question, history):\n",
        "    response = answer_question(question, history)\n",
        "    return response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "bRDJpTtfymFK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "HrlboOxvvetW"
      },
      "outputs": [],
      "source": [
        "# Create a Gradio Interface\n",
        "interface = gr.ChatInterface(fn=gradio_chat_interface)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "RD2Hsg6hvjYA",
        "outputId": "4abf1a36-e236-4fce-da87-7672f3cee6c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://f85f2638e270618caa.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://f85f2638e270618caa.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "# Launch the Gradio Interface\n",
        "interface.launch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "t4dTn2pZXhGy"
      },
      "outputs": [],
      "source": [
        "# res = answer_question(\"What is the price of the iPhone 12?\", [])\n",
        "# res"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO+li/Wz08qKEOtC4ZonwYh"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b2c3e3ec35e3451cb32445920843368f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6c687402d9b94ae5ad29c91bc839f37c",
              "IPY_MODEL_ae88ee4eda7a4b65811dd32b458690fa",
              "IPY_MODEL_40275e9630b64570bdf08d6cad88dc34"
            ],
            "layout": "IPY_MODEL_4daa9e93e7cb4842a6f14699a67bec0e"
          }
        },
        "6c687402d9b94ae5ad29c91bc839f37c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be6f69373db74952bad8015b26f842af",
            "placeholder": "​",
            "style": "IPY_MODEL_1747c633002d47428b44092fc48e8c68",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "ae88ee4eda7a4b65811dd32b458690fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e3cfb865d904f92b7449a036b1fcf4b",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_90fce2dda3f5421aba024005b705601c",
            "value": 2
          }
        },
        "40275e9630b64570bdf08d6cad88dc34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1769640cfbaa405895b4e66ba18d779f",
            "placeholder": "​",
            "style": "IPY_MODEL_5cfe910ed2824bf8a1a9c482c9128e45",
            "value": " 2/2 [00:03&lt;00:00,  1.59s/it]"
          }
        },
        "4daa9e93e7cb4842a6f14699a67bec0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be6f69373db74952bad8015b26f842af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1747c633002d47428b44092fc48e8c68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2e3cfb865d904f92b7449a036b1fcf4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90fce2dda3f5421aba024005b705601c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1769640cfbaa405895b4e66ba18d779f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5cfe910ed2824bf8a1a9c482c9128e45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}